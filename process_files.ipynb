{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading documents from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import tqdm\n",
    "from collections import deque\n",
    "from time import sleep\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Jazz</td>\n",
       "      <td>Jazz music genre originated African-American c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Wikipedia:Protec...</td>\n",
       "      <td>In circumstances pages may need protected modi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Jazz_(disambigua...</td>\n",
       "      <td>Jazz style music subgenres Jazz may also refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Blues</td>\n",
       "      <td>Blues music genre musical form originated Deep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Ragtime</td>\n",
       "      <td>Ragtime also spelled rag-time rag time musical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Unnamed: 0  \\\n",
       "0                 https://en.wikipedia.org/wiki/Jazz   \n",
       "1  https://en.wikipedia.org/wiki/Wikipedia:Protec...   \n",
       "2  https://en.wikipedia.org/wiki/Jazz_(disambigua...   \n",
       "3                https://en.wikipedia.org/wiki/Blues   \n",
       "4              https://en.wikipedia.org/wiki/Ragtime   \n",
       "\n",
       "                                                   0  \n",
       "0  Jazz music genre originated African-American c...  \n",
       "1  In circumstances pages may need protected modi...  \n",
       "2     Jazz style music subgenres Jazz may also refer  \n",
       "3  Blues music genre musical form originated Deep...  \n",
       "4  Ragtime also spelled rag-time rag time musical...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Original file pixels file size MB MIME type image/jpeg http Commons Zero Public Domain Dedicationfalsefalse Click date/time view file appeared time The following wikis use file View global usage file This file contains additional information probably added digital camera scanner used create digitize If file modified original state details may fully reflect modified file'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Unnamed: 0\"] == \"https://en.wikipedia.org/wiki/File:John_Coltrane_1963.jpg\"][\"0\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(texts):\n",
    "  while len(texts) < 1500:\n",
    "    yield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class BFSScraper():\n",
    "    def __init__(self, n_to_visit):\n",
    "        self.n_to_visit = n_to_visit\n",
    "        self.already_visited = set()\n",
    "        self.q = deque()\n",
    "        self.pages_with_error_response = {}\n",
    "        self.pages = OrderedDict() # We want to reproduce the order of visiting pages\n",
    "\n",
    "    def get_unique_n_links(self, links):\n",
    "        \"\"\"This function returns at most n yet not visited links from given list of pages\"\"\"\n",
    "        new_links = []\n",
    "        candidates_ids = np.arange(len(links)) \n",
    "        np.random.shuffle(candidates_ids) # To walk randomly\n",
    "        for candidate_id in candidates_ids: # Possibly all the links could be already visited, or we won't have n links\n",
    "            if len(new_links) > self.n_to_visit:\n",
    "                break\n",
    "            link = \"https://en.wikipedia.org\" + links[candidate_id]['href']\n",
    "            if link not in self.already_visited:\n",
    "                new_links.append(link)\n",
    "            \n",
    "        return new_links\n",
    "\n",
    "    def find_links(self, parsed_page):\n",
    "        links = parsed_page.find_all(\n",
    "            'a', attrs={'href': re.compile(r'^\\/wiki\\/(?!File)(?!Main_Page)\\w*$')})  # To get only wikipedia articles, doen't take files nor something with :, ( etc. Don't go back to main page\n",
    "        \n",
    "        links = list(set(links)) # To remove duplicates, probably not the most efficient way\n",
    "\n",
    "        return links\n",
    "\n",
    "    def process_one_link(self, link):\n",
    "        response = requests.get(link)\n",
    "        if response.status_code != 200:\n",
    "            self.pages_with_error_response[link] = response.status_code\n",
    "            return None\n",
    "        \n",
    "        parsed = bs4.BeautifulSoup(response.text)\n",
    "        found_links = self.find_links(parsed)\n",
    "        n_not_visited_links = self.get_unique_n_links(found_links)\n",
    "        content = \"\".join([p.getText() for p in parsed.find(id=\"mw-content-text\").select('p')])\n",
    "\n",
    "        self.pages[link] = {} # No OrderedDefaultDict :(\n",
    "        self.pages[link][\"content\"] = content\n",
    "        self.pages[link][\"num_of_links\"] = len(found_links)\n",
    "        self.pages[link][\"selected_links\"] = n_not_visited_links\n",
    "\n",
    "        self.already_visited.add(link)\n",
    "        return n_not_visited_links\n",
    "\n",
    "    def dummy_generator(self, n):\n",
    "        while len(self.pages) < n:\n",
    "            yield\n",
    "            \n",
    "    def generate_summary(self):\n",
    "        with open(\"summary.txt\" , 'w') as f:\n",
    "            for link, page in self.pages.items():\n",
    "                f.write(f\"{link} number of reasonable links: {page['num_of_links']}\\n\")\n",
    "                f.write(\"Visited neighbours: \\n\")\n",
    "                for neighbour in page[\"selected_links\"]:\n",
    "                    f.write(f\"\\t\\t{neighbour}\\n\")\n",
    "                f.write(\"\\n\\n\")\n",
    "\n",
    "    def generate_csv(self):\n",
    "        df = pd.DataFrame(self.pages)\n",
    "        df.to_csv('text.csv')\n",
    "        # with open(\"text.csv\" , 'w', encoding=\"utf-8\") as f:\n",
    "        #     for link, page in self.pages.items():\n",
    "        #         f.write(f\"{link}, {page['content'].strip()}\\n\")\n",
    "\n",
    "    def bfs(self, starting_link, n = 1000):\n",
    "        self.q.append(starting_link)\n",
    "        for _ in (pbar := tqdm.tqdm(self.dummy_generator(n))):\n",
    "            link_to_scrap = self.q.popleft()\n",
    "            links_to_visit = self.process_one_link(link_to_scrap)\n",
    "            if links_to_visit is not None: # Succesfull scraping of this particual pages and n neighbours gathered\n",
    "                pbar.set_description(f'{len(self.pages)} sites already collected')\n",
    "                for link in links_to_visit:\n",
    "                    self.q.append(link)\n",
    "\n",
    "            sleep(random.random()*3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2 sites already collected: : 2it [00:02,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "bfs_scrap = BFSScraper(n_to_visit=3)\n",
    "bfs_scrap.bfs('https://en.wikipedia.org/wiki/Jazz', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfs_scrap.generate_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfs_scrap.generate_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "class CustomStemmer():\n",
    "    def __init__(self, data, stemmer=LancasterStemmer, tokenizer=word_tokenize, lemmatizer=WordNetLemmatizer, custom_stopwords=stopwords.words('english')):\n",
    "        self.data = data\n",
    "        self.stemmer = stemmer()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lemmatizer = lemmatizer()\n",
    "        self.custom_stopwords = custom_stopwords\n",
    "\n",
    "    def process_text(self, text, stem = False, lemmatize = True):\n",
    "        words = self.tokenizer(text)\n",
    "        final_words = []  # can't use set to preserve order\n",
    "        for word in words:\n",
    "            if re.match(r'^[A-Za-z]*$', word):\n",
    "                final_words.append(word)\n",
    "        cleaned = [\n",
    "            word for word in final_words if word not in self.custom_stopwords]\n",
    "        \n",
    "        text = ' '.join(cleaned)\n",
    "        if stem:\n",
    "            text = self.stemmer.stem(text)\n",
    "        elif lemmatize:\n",
    "            text = self.lemmatizer.lemmatize(text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def process_corpus(self):\n",
    "        self.processed = {index: self.process_text(element['content']) for index, element in self.data.iterrows()}\n",
    "        return self.processed\n",
    "\n",
    "    def generate_csv(self):\n",
    "        df = pd.DataFrame(self.processed, index=[0]).T\n",
    "        df.columns = ['text']\n",
    "        df.to_csv('processed.csv', columns=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>num_of_links</th>\n",
       "      <th>selected_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://en.wikipedia.org/wiki/Jazz</th>\n",
       "      <td>\\nJazz is a music genre that originated in the...</td>\n",
       "      <td>863</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Danish_jazz', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://en.wikipedia.org/wiki/Danish_jazz</th>\n",
       "      <td>Danish jazz dates back to 1923 when Valdemar E...</td>\n",
       "      <td>284</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Big_band', 'ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     content  \\\n",
       "https://en.wikipedia.org/wiki/Jazz         \\nJazz is a music genre that originated in the...   \n",
       "https://en.wikipedia.org/wiki/Danish_jazz  Danish jazz dates back to 1923 when Valdemar E...   \n",
       "\n",
       "                                          num_of_links  \\\n",
       "https://en.wikipedia.org/wiki/Jazz                 863   \n",
       "https://en.wikipedia.org/wiki/Danish_jazz          284   \n",
       "\n",
       "                                                                              selected_links  \n",
       "https://en.wikipedia.org/wiki/Jazz         ['https://en.wikipedia.org/wiki/Danish_jazz', ...  \n",
       "https://en.wikipedia.org/wiki/Danish_jazz  ['https://en.wikipedia.org/wiki/Big_band', 'ht...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = pd.read_csv('text.csv', index_col=0).T\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = CustomStemmer(texts, PorterStemmer, word_tokenize)\n",
    "preprocessed = stemmer.process_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer.generate_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files available [here](https://drive.google.com/drive/folders/1FkuFF7tCvBj8pTVDtOtFXtfSUOH7a2vw?usp=sharing), as git doesn't support so large files "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d938c375e6e2a2b94db19e540527a5d7d80fbd1055fc33c5eeb59a5dcfa9a532"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
